---
layout: post
title:  "Super Convergence on CIFAR-10"
description: ""
date:   2022-12-29 10:05:45
categories:
- software
tags:
- machinelearning-1
- machinelearning
comments: true
---

In this post I'm trying to explore the superconvergence technique introduced by Leslie Smith from the Naval Research Laboratory, more of it in 
- [Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)
- [Training Imagenet in 3 hours for USD 25; and CIFAR10 for USD 0.26](https://www.fast.ai/posts/2018-04-30-dawnbench-fastai.html)
- [AdamW and Super-convergence is now the fastest way to train neural nets](https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html)
- https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138

<div>
  <img id="ads_logo" alt="ads" src="/public/images/ads.png" style="max-width: 20px;" />
  <div class="image-grid">
    {% include page_tags_list_books.html %}
  </div>
</div>
